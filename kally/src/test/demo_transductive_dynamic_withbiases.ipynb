{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c50ce3e-75c1-4505-9daf-133e056adf24",
   "metadata": {},
   "source": [
    "### Prepare Relevant imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1686c9dc-55dd-40de-a3a8-fc95f689c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "import torch_geometric as tg\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "gat_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(gat_path)\n",
    "from gat import Layer_Attention_Dynamic_GATWithBias, Layer_Attention_MultiHead_GAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e905c-c564-4f6f-a65e-998041fc14eb",
   "metadata": {},
   "source": [
    "### Preparing the data (the unique graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4b33c-0e51-4bb4-bedd-3be3a74f3ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tg.datasets.Planetoid(root='data', name='Cora', split='full')\n",
    "cora_dataloader = tg.loader.DataLoader(dataset)\n",
    "cora_graph = next(iter(cora_dataloader))\n",
    "\n",
    "nodes = cora_graph.x\n",
    "y = cora_graph.y\n",
    "adjacency_matrix = tg.utils.to_dense_adj(cora_graph.edge_index).squeeze(dim=0)\n",
    "\n",
    "train_mask = cora_graph.train_mask\n",
    "test_mask = cora_graph.test_mask\n",
    "val_mask = cora_graph.val_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10a18b-d1b7-4dc8-83bd-c5f7e72210f1",
   "metadata": {},
   "source": [
    "### Preparing Model and Optimisers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b3593c-8f2b-48ab-ac1f-3aa70bce9473",
   "metadata": {},
   "source": [
    "The dynamic attention which adds trainable biases before computing a LeakyReLU requires us to know the number of nodes in the graph in advance. Because of this limitation we construct the model classes inside the experiments directly in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6697553-1fd2-45a2-95ff-0a5b49c0b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_Transductive_DynamicBiases_CORA(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(GAT_Transductive_DynamicBiases_CORA, self).__init__()\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(p=0.6)\n",
    "        self.attention_layer_1 = Layer_Attention_Dynamic_GATWithBias(input_dim=input_dim,\n",
    "                                                               repr_dim=8,\n",
    "                                                               n_heads=8,\n",
    "                                                               n_nodes=2708,\n",
    "                                                               epsilon_bias=1.0,\n",
    "                                                               alpha=0.2,\n",
    "                                                               attention_aggr='concat',\n",
    "                                                               dropout=0.6)\n",
    "        self.activation_1 = nn.ELU()\n",
    "\n",
    "        self.dropout_2 = nn.Dropout(p=0.6)\n",
    "        self.attention_layer_2 = Layer_Attention_Dynamic_GATWithBias(input_dim=64,\n",
    "                                                               repr_dim=num_classes,\n",
    "                                                               n_heads=1,\n",
    "                                                               n_nodes=2708,\n",
    "                                                               epsilon_bias=1.0,\n",
    "                                                               alpha=0.2,\n",
    "                                                               attention_aggr='concat',\n",
    "                                                               dropout=0.6)\n",
    "\n",
    "    def forward(self, node_matrix, adj_matrix):\n",
    "        node_matrix_dropout = self.dropout_1(node_matrix)\n",
    "\n",
    "        z_1 = self.attention_layer_1(node_matrix_dropout, adj_matrix)\n",
    "        a_1 = self.activation_1(z_1)\n",
    "\n",
    "        a_1_dropout = self.dropout_2(a_1)\n",
    "        \n",
    "        z_2 = self.attention_layer_2(a_1_dropout, adj_matrix)\n",
    "\n",
    "        return z_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c69c68-3f0b-412b-84c7-525b2eb424ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default values from GAT paper\n",
    "lr = 0.01\n",
    "weight_decay = 0.005\n",
    "# lr = 0.05\n",
    "# weight_decay = 0.05\n",
    "\n",
    "trans_model = GAT_Transductive_DynamicBiases_CORA(1433, 7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(trans_model.parameters(), \n",
    "                       lr=lr, \n",
    "                       weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ba498-4d53-4af3-b1f3-4f6ce11a18f6",
   "metadata": {},
   "source": [
    "### Running training with (very) simple early stopping with 20 epochs tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd8a5c2-1ae9-489e-88a6-4916b3bf6b11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 improved validation accuracy to: 0.502\n",
      "PRINTING TEST ACCURACY: 0.482\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 2 improved validation accuracy to: 0.578\n",
      "PRINTING TEST ACCURACY: 0.559\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 3 improved validation accuracy to: 0.644\n",
      "PRINTING TEST ACCURACY: 0.632\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 4 improved validation accuracy to: 0.692\n",
      "PRINTING TEST ACCURACY: 0.687\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 5 improved validation accuracy to: 0.746\n",
      "PRINTING TEST ACCURACY: 0.737\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 6 improved validation accuracy to: 0.788\n",
      "PRINTING TEST ACCURACY: 0.798\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 7 improved validation accuracy to: 0.816\n",
      "PRINTING TEST ACCURACY: 0.832\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 8 improved validation accuracy to: 0.836\n",
      "PRINTING TEST ACCURACY: 0.843\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 9 improved validation accuracy to: 0.838\n",
      "PRINTING TEST ACCURACY: 0.851\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 10 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 11 improved validation accuracy to: 0.846\n",
      "PRINTING TEST ACCURACY: 0.863\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 12 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 13 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 14 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 15 improved validation accuracy to: 0.848\n",
      "PRINTING TEST ACCURACY: 0.87\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 16 improved validation accuracy to: 0.85\n",
      "PRINTING TEST ACCURACY: 0.872\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 17 improved validation accuracy to: 0.852\n",
      "PRINTING TEST ACCURACY: 0.873\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 18 improved validation accuracy to: 0.858\n",
      "PRINTING TEST ACCURACY: 0.877\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 19 improved validation accuracy to: 0.86\n",
      "PRINTING TEST ACCURACY: 0.879\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 20 improved validation accuracy to: 0.864\n",
      "PRINTING TEST ACCURACY: 0.88\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 21 improved validation accuracy to: 0.87\n",
      "PRINTING TEST ACCURACY: 0.873\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 22 improved validation accuracy to: 0.872\n",
      "PRINTING TEST ACCURACY: 0.871\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 23 improved validation accuracy to: 0.874\n",
      "PRINTING TEST ACCURACY: 0.871\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 24 improved validation accuracy to: 0.878\n",
      "PRINTING TEST ACCURACY: 0.87\n",
      "SAVING MODEL to trans_model_dynamicbias.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 25 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 26 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 27 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 28 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 29 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 30 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 31 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 32 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 33 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 34 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 35 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 36 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 37 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 38 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 39 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 40 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 41 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 42 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "EPOCH 43 did not improve validation accuracy\n",
      "Tolerance 20 epochs reached, exiting\n"
     ]
    }
   ],
   "source": [
    "tolerance = 0\n",
    "best_val_accuracy = 0\n",
    "\n",
    "for epoch in range(300):\n",
    "    trans_model.train()\n",
    "    \n",
    "    output = trans_model(nodes, adjacency_matrix)\n",
    "    loss = criterion(output[train_mask], y[train_mask])\n",
    "    \n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    # compute validatio accuracy to fascilitate early stopping if needed\n",
    "    trans_model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = trans_model(nodes, adjacency_matrix)\n",
    "        current_val_accuracy = (output[val_mask].argmax(dim=1) == y[val_mask]).sum().item() / val_mask.sum().item()\n",
    "    \n",
    "    if current_val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = current_val_accuracy\n",
    "        tolerance = 0\n",
    "        print(f'EPOCH {epoch+1} improved validation accuracy to: {current_val_accuracy}')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = trans_model(nodes, adjacency_matrix)\n",
    "            test_accuracy = (output[test_mask].argmax(dim=1) == y[test_mask]).sum().item() / test_mask.sum().item()\n",
    "            print(f'PRINTING TEST ACCURACY: {test_accuracy}')\n",
    "        print('SAVING MODEL to trans_model_dynamicbias.pt')\n",
    "        torch.save(trans_model.state_dict(), 'trans_model_dynamicbias.pt')\n",
    "        \n",
    "    else:\n",
    "        tolerance += 1\n",
    "        print(f'EPOCH {epoch+1} did not improve validation accuracy')\n",
    "        \n",
    "        if tolerance == 19:\n",
    "            print('Tolerance 20 epochs reached, exiting')\n",
    "            break\n",
    "    print('----------------------------------------------- \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495f993-3a52-40b6-81bc-cb96d8ac01bd",
   "metadata": {},
   "source": [
    "### Printing the final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64144d1-2005-439b-8dce-154cdca45c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL test accuracy is: 0.865\n"
     ]
    }
   ],
   "source": [
    "trans_model.load_state_dict(torch.load('trans_model_dynamicbias.pt'))\n",
    "trans_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = trans_model(nodes, adjacency_matrix)\n",
    "    final_test_accuracy = (output[test_mask].argmax(dim=1) == y[test_mask]).sum().item() / test_mask.sum().item()\n",
    "    print(f'FINAL test accuracy is: {final_test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

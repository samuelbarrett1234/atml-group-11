{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7914495c",
   "metadata": {},
   "source": [
    "# Transductive Transformer experiments on CORA\n",
    "\n",
    "By Sam Barrett.\n",
    "These follow essentially the same steps as Kally's GAT experiments on CORA.\n",
    "Most of the setup is copied from `demo_kally_transductive_cora`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb2e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "import torch_geometric as tg\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "gat_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(gat_path)\n",
    "from gat import VanillaTransformer_Transductive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfeb0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tg.datasets.Planetoid(root='data', name='Cora', split='full')\n",
    "cora_dataloader = tg.loader.DataLoader(dataset)\n",
    "cora_graph = next(iter(cora_dataloader))\n",
    "\n",
    "nodes = cora_graph.x\n",
    "y = cora_graph.y\n",
    "adjacency_matrix = tg.utils.to_dense_adj(cora_graph.edge_index).squeeze(dim=0)\n",
    "\n",
    "train_mask = cora_graph.train_mask\n",
    "test_mask = cora_graph.test_mask\n",
    "val_mask = cora_graph.val_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d115d7b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1.0e-1\n",
    "weight_decay = 3.0e-5\n",
    "\n",
    "MODEL_FILENAME = 'vanilla_transformer_model.pt'\n",
    "model = VanillaTransformer_Transductive(1433, 7, 64, 2, 8, dropout_hidden=0.1,\n",
    "                                        identity_bias=0.02)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(model.parameters(), \n",
    "                       lr=lr, weight_decay=weight_decay)\n",
    "sched = optim.lr_scheduler.StepLR(optimiser, 50, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "964dda0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss = 2.2685842514038086\n",
      "EPOCH 1 improved validation accuracy to: 0.316\n",
      "PRINTING TEST ACCURACY: 0.319\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 2.195664882659912\n",
      "EPOCH 2 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 2.070953607559204\n",
      "EPOCH 3 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.99169921875\n",
      "EPOCH 4 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.9254754781723022\n",
      "EPOCH 5 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8780906200408936\n",
      "EPOCH 6 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8588660955429077\n",
      "EPOCH 7 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8577238321304321\n",
      "EPOCH 8 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8632115125656128\n",
      "EPOCH 9 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8714735507965088\n",
      "EPOCH 10 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8759931325912476\n",
      "EPOCH 11 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8730989694595337\n",
      "EPOCH 12 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.866565465927124\n",
      "EPOCH 13 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8593640327453613\n",
      "EPOCH 14 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8496495485305786\n",
      "EPOCH 15 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8375790119171143\n",
      "EPOCH 16 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8233267068862915\n",
      "EPOCH 17 improved validation accuracy to: 0.4\n",
      "PRINTING TEST ACCURACY: 0.409\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.8019989728927612\n",
      "EPOCH 18 improved validation accuracy to: 0.448\n",
      "PRINTING TEST ACCURACY: 0.438\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.7770363092422485\n",
      "EPOCH 19 improved validation accuracy to: 0.456\n",
      "PRINTING TEST ACCURACY: 0.438\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.7440112829208374\n",
      "EPOCH 20 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.7147457599639893\n",
      "EPOCH 21 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.7035037279129028\n",
      "EPOCH 22 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.767895221710205\n",
      "EPOCH 23 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.6235885620117188\n",
      "EPOCH 24 improved validation accuracy to: 0.458\n",
      "PRINTING TEST ACCURACY: 0.441\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.6012214422225952\n",
      "EPOCH 25 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.5716841220855713\n",
      "EPOCH 26 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.5447192192077637\n",
      "EPOCH 27 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.5232198238372803\n",
      "EPOCH 28 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.500363826751709\n",
      "EPOCH 29 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.4884744882583618\n",
      "EPOCH 30 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.4732351303100586\n",
      "EPOCH 31 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.4536700248718262\n",
      "EPOCH 32 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.4463295936584473\n",
      "EPOCH 33 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.431258201599121\n",
      "EPOCH 34 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.4294025897979736\n",
      "EPOCH 35 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.6751430034637451\n",
      "EPOCH 36 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.385299563407898\n",
      "EPOCH 37 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.456119418144226\n",
      "EPOCH 38 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.3564038276672363\n",
      "EPOCH 39 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.3582956790924072\n",
      "EPOCH 40 improved validation accuracy to: 0.472\n",
      "PRINTING TEST ACCURACY: 0.454\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.3078176975250244\n",
      "EPOCH 41 improved validation accuracy to: 0.502\n",
      "PRINTING TEST ACCURACY: 0.488\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.2908403873443604\n",
      "EPOCH 42 improved validation accuracy to: 0.536\n",
      "PRINTING TEST ACCURACY: 0.519\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.2173832654953003\n",
      "EPOCH 43 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.2463077306747437\n",
      "EPOCH 44 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.2833795547485352\n",
      "EPOCH 45 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.1984165906906128\n",
      "EPOCH 46 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.1674481630325317\n",
      "EPOCH 47 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.173906683921814\n",
      "EPOCH 48 improved validation accuracy to: 0.54\n",
      "PRINTING TEST ACCURACY: 0.532\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.1430362462997437\n",
      "EPOCH 49 improved validation accuracy to: 0.542\n",
      "PRINTING TEST ACCURACY: 0.524\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.126672625541687\n",
      "EPOCH 50 improved validation accuracy to: 0.552\n",
      "PRINTING TEST ACCURACY: 0.521\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.0895037651062012\n",
      "EPOCH 51 improved validation accuracy to: 0.564\n",
      "PRINTING TEST ACCURACY: 0.52\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.0451488494873047\n",
      "EPOCH 52 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.0515679121017456\n",
      "EPOCH 53 improved validation accuracy to: 0.568\n",
      "PRINTING TEST ACCURACY: 0.531\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.0065116882324219\n",
      "EPOCH 54 improved validation accuracy to: 0.584\n",
      "PRINTING TEST ACCURACY: 0.567\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.9895660281181335\n",
      "EPOCH 55 improved validation accuracy to: 0.6\n",
      "PRINTING TEST ACCURACY: 0.572\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss = 0.9683818817138672\n",
      "EPOCH 56 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.9475275278091431\n",
      "EPOCH 57 improved validation accuracy to: 0.676\n",
      "PRINTING TEST ACCURACY: 0.633\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.9050538539886475\n",
      "EPOCH 58 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.9258151054382324\n",
      "EPOCH 59 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.9561179280281067\n",
      "EPOCH 60 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.9318699836730957\n",
      "EPOCH 61 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.8259556293487549\n",
      "EPOCH 62 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.8748263120651245\n",
      "EPOCH 63 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.787102460861206\n",
      "EPOCH 64 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.9160788655281067\n",
      "EPOCH 65 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.9079745411872864\n",
      "EPOCH 66 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.7578139901161194\n",
      "EPOCH 67 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.7995103597640991\n",
      "EPOCH 68 improved validation accuracy to: 0.692\n",
      "PRINTING TEST ACCURACY: 0.641\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.6639853119850159\n",
      "EPOCH 69 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.6664349436759949\n",
      "EPOCH 70 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.6643559336662292\n",
      "EPOCH 71 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.6012776494026184\n",
      "EPOCH 72 improved validation accuracy to: 0.716\n",
      "PRINTING TEST ACCURACY: 0.669\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.6348301768302917\n",
      "EPOCH 73 improved validation accuracy to: 0.726\n",
      "PRINTING TEST ACCURACY: 0.669\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5876689553260803\n",
      "EPOCH 74 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5951030254364014\n",
      "EPOCH 75 improved validation accuracy to: 0.732\n",
      "PRINTING TEST ACCURACY: 0.681\n",
      "SAVING MODEL to vanilla_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5363351702690125\n",
      "EPOCH 76 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5261126160621643\n",
      "EPOCH 77 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.6337152123451233\n",
      "EPOCH 78 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.47313427925109863\n",
      "EPOCH 79 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.589490532875061\n",
      "EPOCH 80 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5204784274101257\n",
      "EPOCH 81 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4986553192138672\n",
      "EPOCH 82 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4706607758998871\n",
      "EPOCH 83 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.47021475434303284\n",
      "EPOCH 84 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4766632914543152\n",
      "EPOCH 85 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4644465744495392\n",
      "EPOCH 86 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.428827702999115\n",
      "EPOCH 87 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4587513506412506\n",
      "EPOCH 88 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5457830429077148\n",
      "EPOCH 89 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.48605331778526306\n",
      "EPOCH 90 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.49013206362724304\n",
      "EPOCH 91 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.46572068333625793\n",
      "EPOCH 92 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5012149810791016\n",
      "EPOCH 93 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4843548536300659\n",
      "EPOCH 94 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4986873269081116\n",
      "EPOCH 95 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4866921603679657\n",
      "EPOCH 96 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.49178314208984375\n",
      "EPOCH 97 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.49576255679130554\n",
      "EPOCH 98 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4660320580005646\n",
      "EPOCH 99 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.46243801712989807\n",
      "EPOCH 100 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.45381098985671997\n",
      "EPOCH 101 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.41692256927490234\n",
      "EPOCH 102 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4650455415248871\n",
      "EPOCH 103 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4929502308368683\n",
      "EPOCH 104 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5170495510101318\n",
      "EPOCH 105 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.525436520576477\n",
      "EPOCH 106 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5170060992240906\n",
      "EPOCH 107 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5226266384124756\n",
      "EPOCH 108 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4787386953830719\n",
      "EPOCH 109 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.479606032371521\n",
      "EPOCH 110 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.46725934743881226\n",
      "EPOCH 111 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5089569091796875\n",
      "EPOCH 112 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5839207172393799\n",
      "EPOCH 113 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5034934282302856\n",
      "EPOCH 114 did not improve validation accuracy\n",
      "Tolerance 40 epochs reached, exiting\n"
     ]
    }
   ],
   "source": [
    "tolerance = 0\n",
    "MAX_TOL = 40\n",
    "best_val_accuracy = 0\n",
    "\n",
    "for epoch in range(300):\n",
    "    model.train()\n",
    "    \n",
    "    output = model(nodes, adjacency_matrix)\n",
    "    loss = criterion(output[train_mask], y[train_mask])\n",
    "    print(\"Training loss =\", float(loss))\n",
    "    \n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    sched.step()\n",
    "    \n",
    "    # compute validatio accuracy to fascilitate early stopping if needed\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(nodes, adjacency_matrix)\n",
    "        current_val_accuracy = (output[val_mask].argmax(dim=1) == y[val_mask]).sum().item() / val_mask.sum().item()\n",
    "        test_accuracy = (output[test_mask].argmax(dim=1) == y[test_mask]).sum().item() / test_mask.sum().item()\n",
    "\n",
    "    if current_val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = current_val_accuracy\n",
    "        tolerance = 0\n",
    "        print(f'EPOCH {epoch+1} improved validation accuracy to: {current_val_accuracy}')\n",
    "        print(f'PRINTING TEST ACCURACY: {test_accuracy}')\n",
    "        print('SAVING MODEL to', MODEL_FILENAME)\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)\n",
    "        \n",
    "    else:\n",
    "        tolerance += 1\n",
    "        print(f'EPOCH {epoch+1} did not improve validation accuracy')\n",
    "        \n",
    "        if tolerance == MAX_TOL - 1:\n",
    "            print(f'Tolerance {MAX_TOL} epochs reached, exiting')\n",
    "            break\n",
    "    print('----------------------------------------------- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "455df622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL test accuracy is: 0.715\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(nodes, adjacency_matrix)\n",
    "    final_test_accuracy = (output[test_mask].argmax(dim=1) == y[test_mask]).sum().item() / test_mask.sum().item()\n",
    "    print(f'FINAL test accuracy is: {final_test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383d4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

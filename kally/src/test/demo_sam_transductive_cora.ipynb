{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7914495c",
   "metadata": {},
   "source": [
    "# Transductive Transformer experiments on CORA\n",
    "\n",
    "By Sam Barrett.\n",
    "These follow essentially the same steps as Kally's GAT experiments on CORA.\n",
    "Most of the training loop and data management code was taken from `demo_kally_transductive_cora`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb2e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "import torch_geometric as tg\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "gat_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(gat_path)\n",
    "from gat import VanillaTransformer_Transductive, UniversalTransformer_Transductive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfeb0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tg.datasets.Planetoid(root='data', name='Cora', split='full')\n",
    "cora_dataloader = tg.loader.DataLoader(dataset)\n",
    "cora_graph = next(iter(cora_dataloader))\n",
    "\n",
    "nodes = cora_graph.x\n",
    "y = cora_graph.y\n",
    "adjacency_matrix = tg.utils.to_dense_adj(cora_graph.edge_index).squeeze(dim=0)\n",
    "\n",
    "train_mask = cora_graph.train_mask\n",
    "test_mask = cora_graph.test_mask\n",
    "val_mask = cora_graph.val_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d115d7b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1.0e-3\n",
    "weight_decay = 0.0\n",
    "\n",
    "MODEL_FILENAME = 'universal_transformer_model.pt'\n",
    "model = UniversalTransformer_Transductive(1433, 7, 64, 2, 8, dropout_hidden=0.1,\n",
    "                                          identity_bias=0.02)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(model.parameters(), \n",
    "                       lr=lr, weight_decay=weight_decay)\n",
    "sched = optim.lr_scheduler.StepLR(optimiser, 50, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "964dda0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss = 2.068263292312622\n",
      "EPOCH 1 improved validation accuracy to: 0.396\n",
      "PRINTING TEST ACCURACY: 0.388\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.7409734725952148\n",
      "EPOCH 2 improved validation accuracy to: 0.404\n",
      "PRINTING TEST ACCURACY: 0.403\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.5542259216308594\n",
      "EPOCH 3 improved validation accuracy to: 0.572\n",
      "PRINTING TEST ACCURACY: 0.562\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.320908546447754\n",
      "EPOCH 4 improved validation accuracy to: 0.704\n",
      "PRINTING TEST ACCURACY: 0.706\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 1.1426247358322144\n",
      "EPOCH 5 improved validation accuracy to: 0.746\n",
      "PRINTING TEST ACCURACY: 0.738\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.969194233417511\n",
      "EPOCH 6 improved validation accuracy to: 0.764\n",
      "PRINTING TEST ACCURACY: 0.766\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.8400485515594482\n",
      "EPOCH 7 improved validation accuracy to: 0.806\n",
      "PRINTING TEST ACCURACY: 0.796\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.7261431217193604\n",
      "EPOCH 8 improved validation accuracy to: 0.824\n",
      "PRINTING TEST ACCURACY: 0.82\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.6361779570579529\n",
      "EPOCH 9 improved validation accuracy to: 0.84\n",
      "PRINTING TEST ACCURACY: 0.847\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.5513914823532104\n",
      "EPOCH 10 improved validation accuracy to: 0.844\n",
      "PRINTING TEST ACCURACY: 0.853\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.4872429072856903\n",
      "EPOCH 11 improved validation accuracy to: 0.862\n",
      "PRINTING TEST ACCURACY: 0.856\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.433452844619751\n",
      "EPOCH 12 improved validation accuracy to: 0.87\n",
      "PRINTING TEST ACCURACY: 0.854\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.3887445032596588\n",
      "EPOCH 13 improved validation accuracy to: 0.874\n",
      "PRINTING TEST ACCURACY: 0.856\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.34911587834358215\n",
      "EPOCH 14 improved validation accuracy to: 0.89\n",
      "PRINTING TEST ACCURACY: 0.861\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.3157540261745453\n",
      "EPOCH 15 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.28864315152168274\n",
      "EPOCH 16 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.2619530260562897\n",
      "EPOCH 17 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.24148382246494293\n",
      "EPOCH 18 improved validation accuracy to: 0.894\n",
      "PRINTING TEST ACCURACY: 0.864\n",
      "SAVING MODEL to universal_transformer_model.pt\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.22793012857437134\n",
      "EPOCH 19 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.21222613751888275\n",
      "EPOCH 20 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.1988961100578308\n",
      "EPOCH 21 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.18502497673034668\n",
      "EPOCH 22 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.1709817349910736\n",
      "EPOCH 23 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.16368627548217773\n",
      "EPOCH 24 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.15597771108150482\n",
      "EPOCH 25 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.14405842125415802\n",
      "EPOCH 26 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.1355614960193634\n",
      "EPOCH 27 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.12776398658752441\n",
      "EPOCH 28 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.12128408998250961\n",
      "EPOCH 29 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.11479659378528595\n",
      "EPOCH 30 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.10673939436674118\n",
      "EPOCH 31 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.10588578879833221\n",
      "EPOCH 32 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.09780881553888321\n",
      "EPOCH 33 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.09178595244884491\n",
      "EPOCH 34 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.08522794395685196\n",
      "EPOCH 35 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.08069748431444168\n",
      "EPOCH 36 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.0782996118068695\n",
      "EPOCH 37 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.07579146325588226\n",
      "EPOCH 38 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.07031777501106262\n",
      "EPOCH 39 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.06574508547782898\n",
      "EPOCH 40 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.06490104645490646\n",
      "EPOCH 41 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.05975664407014847\n",
      "EPOCH 42 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.0573648177087307\n",
      "EPOCH 43 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.055276237428188324\n",
      "EPOCH 44 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.052391331642866135\n",
      "EPOCH 45 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.0484362356364727\n",
      "EPOCH 46 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.05018950253725052\n",
      "EPOCH 47 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.04567641019821167\n",
      "EPOCH 48 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.04419168829917908\n",
      "EPOCH 49 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.04285541921854019\n",
      "EPOCH 50 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.04071159288287163\n",
      "EPOCH 51 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.03883611410856247\n",
      "EPOCH 52 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.039546363055706024\n",
      "EPOCH 53 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.03581589460372925\n",
      "EPOCH 54 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss = 0.033687248826026917\n",
      "EPOCH 55 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.03312468156218529\n",
      "EPOCH 56 did not improve validation accuracy\n",
      "----------------------------------------------- \n",
      "\n",
      "Training loss = 0.033340632915496826\n",
      "EPOCH 57 did not improve validation accuracy\n",
      "Tolerance 40 epochs reached, exiting\n"
     ]
    }
   ],
   "source": [
    "tolerance = 0\n",
    "MAX_TOL = 40\n",
    "best_val_accuracy = 0\n",
    "\n",
    "for epoch in range(300):\n",
    "    model.train()\n",
    "    \n",
    "    output = model(nodes, adjacency_matrix)\n",
    "    loss = criterion(output[train_mask], y[train_mask])\n",
    "    print(\"Training loss =\", float(loss))\n",
    "    \n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    sched.step()\n",
    "    \n",
    "    # compute validatio accuracy to fascilitate early stopping if needed\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(nodes, adjacency_matrix)\n",
    "        current_val_accuracy = (output[val_mask].argmax(dim=1) == y[val_mask]).sum().item() / val_mask.sum().item()\n",
    "        test_accuracy = (output[test_mask].argmax(dim=1) == y[test_mask]).sum().item() / test_mask.sum().item()\n",
    "\n",
    "    if current_val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = current_val_accuracy\n",
    "        tolerance = 0\n",
    "        print(f'EPOCH {epoch+1} improved validation accuracy to: {current_val_accuracy}')\n",
    "        print(f'PRINTING TEST ACCURACY: {test_accuracy}')\n",
    "        print('SAVING MODEL to', MODEL_FILENAME)\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)\n",
    "        \n",
    "    else:\n",
    "        tolerance += 1\n",
    "        print(f'EPOCH {epoch+1} did not improve validation accuracy')\n",
    "        \n",
    "        if tolerance == MAX_TOL - 1:\n",
    "            print(f'Tolerance {MAX_TOL} epochs reached, exiting')\n",
    "            break\n",
    "    print('----------------------------------------------- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455df622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL test accuracy is: 0.864\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(nodes, adjacency_matrix)\n",
    "    final_test_accuracy = (output[test_mask].argmax(dim=1) == y[test_mask]).sum().item() / test_mask.sum().item()\n",
    "    print(f'FINAL test accuracy is: {final_test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383d4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
